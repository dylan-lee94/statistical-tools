{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utility'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e547162095ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Local Import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mutility\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utility'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm,t \n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Local Import\n",
    "from utility import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'load_data' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-484608370eb9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DASH_merged.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "df = load_data('DASH_merged.txt')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Returns\n",
    "r = df['logclose'].pct_change().dropna()\n",
    "# r = r.resample('D').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VaR Caclulation for increasing Time Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Inital Test Window Size and alpha\n",
    "tau = 20\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value at Risk - Non-Parametric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to collect VaR\n",
    "VaR_H = []\n",
    "\n",
    "for i in range(len(returns)-tau):\n",
    "  #Parameters\n",
    "  ts = returns[:tau+i]\n",
    "\n",
    "  #VaR\n",
    "  VaR_H.append(ts.quantile(alpha)) \n",
    "  \n",
    "  N = len(ts)\n",
    "  ts_sorted = ts.sort_values()\n",
    "\n",
    "# Plotting\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(returns[tau:])\n",
    "ax.plot(returns[tau:].index,VaR_H, label='VaR')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_title('VaR estimation using the Historical Simulation Method')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value at Risk - Normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to collect VaR\n",
    "VaR_N = []\n",
    "\n",
    "for i in range(0,len(returns)-tau):\n",
    "  #Parameters\n",
    "  ts = returns[0:tau+i]\n",
    "  mu_norm, sig_norm = norm.fit(ts)\n",
    "\n",
    "  #VaR\n",
    "  VaR_N.append(mu_norm+sig_norm*norm.ppf(1-alpha)) \n",
    "\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(returns[tau:])\n",
    "ax.plot(returns[tau:].index,-1*np.array(VaR_N), label='VaR')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_title('VaR estimation using the Normal Distribution')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value at Risk - Student's t-Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to collect VaR\n",
    "VaR_T = []\n",
    "\n",
    "for i in range(0,len(returns)-tau):\n",
    "  #Parameters\n",
    "  ts = returns[0:tau+i]\n",
    "  # mu_norm = np.mean(ts)\n",
    "  # sig_norm = np.std(ts)\n",
    "  mu_norm, sig_norm = norm.fit(ts)\n",
    "  nu, mu_t, sig_t = t.fit(ts)\n",
    "\n",
    "  sig_t = ((nu-2)/nu)**0.5 * sig_norm\n",
    "\n",
    "  #VaR\n",
    "  VaR_T.append(mu_norm + sig_t* t.ppf(1-0.05,nu))\n",
    "\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(returns[tau:])\n",
    "ax.plot(returns[tau:].index,-1*np.array(VaR_T), label='VaR')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_title(\"VaR estimation using the Student's t-Distribution\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAR & ES  - Parametric (EWMA) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initiate the EWMA using a warm-up phase to set up the standard deviation.\n",
    "\n",
    "tau=20\n",
    "\n",
    "Lambda = 0.94\n",
    "Sigma2     = [returns[0]**2]\n",
    "\n",
    "\n",
    "for j in range(1,tau):\n",
    "  Sigma2.append((1-Lambda) * returns[j-1]**2 + Lambda * Sigma2[j-1])\n",
    "\n",
    "\n",
    "#Preallocate\n",
    "VaR_EWM = []\n",
    "CVaR_EWM = []\n",
    "\n",
    "for j in range(tau,len(returns)):    \n",
    "    Sigma2.append(Lambda* Sigma2[j-1]+(1-Lambda)*returns[j-1]**2)\n",
    "    std = np.sqrt(Sigma2[j])\n",
    "    \n",
    "    #Parametrs\n",
    "    # mu = returns[:t].ewm(alpha=0.94).mean()[-1]\n",
    "\n",
    "    #VaR \n",
    "    VaR_EWM.append(std*norm.ppf(1-alpha)) \n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(returns[tau:])\n",
    "ax.plot(returns[tau:].index,-1*np.array(VaR_EWM), label='VaR')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_title('VaR estimation using the EWM Method')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#%% Literature\n",
    "\n",
    "# https://de.mathworks.com/help/risk/value-at-risk-estimation-and-backtesting-1.html\n",
    "# https://mmquant.net/introduction-to-volatility-models-with-matlab-sma-ewma-cc-range-estimators/\n",
    "# https://uk.mathworks.com/help/risk/overview-of-var-backtesting.html\n",
    "# https://www.investopedia.com/articles/professionals/081215/backtesting-valueatrisk-var-basics.asp\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37064bitmyenvconda797eddfcb8154d73ad30d65fc4fa6ada",
   "display_name": "Python 3.7.0 64-bit ('myenv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
